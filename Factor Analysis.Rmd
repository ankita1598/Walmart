---
title: "Assignment 5"
author: "Lokesh Arora, Ankita Shinde"
date: "10/8/2020"
output:
  word_document: default
  pdf_document: default
Github Link: https://github.com/ankita1598/Walmart
---
```{r}
#Loading Packages
library(mvtnorm)
library(dplyr)
library(psych)
library(lubridate)
library("plyr")
library("ggplot2")
library(RColorBrewer)
library("dplyr")
```

```{r}
#Loading Dataset
dataset = read.csv("data.csv", header= T)
head(dataset)
```

```{r}
#We can see that there are few null values in the data set for column Markdown 1 - 5. We will also split the data column in 3 as Day, Month and Year.
dataset$Year <- year(ymd(dataset$Date))
dataset$Month <- month(ymd(dataset$Date)) 
dataset$Day <- day(ymd(dataset$Date))
dataset$Dept = as.factor(dataset$Dept)
dataset$Store = as.factor(dataset$Store)
dataset$MarkDown1[is.na(dataset$MarkDown1)] = 0
dataset$MarkDown2[is.na(dataset$MarkDown2)] = 0
dataset$MarkDown3[is.na(dataset$MarkDown3)] = 0
dataset$MarkDown4[is.na(dataset$MarkDown4)] = 0
dataset$MarkDown5[is.na(dataset$MarkDown5)] = 0
dataset = fastDummies::dummy_cols(dataset, select_columns = "Type")
dataset$IsHoliday[dataset$isHoliday == "False"] = 0
dataset$IsHoliday[dataset$isHoliday == "True"] = 1
head(dataset)
```

```{r}
dim(dataset)
```
```{r}
names(dataset)
```

```{r}
#correlation
dataset$Dept = as.numeric(as.factor(dataset$Dept))
dataset$Store = as.numeric(as.factor(dataset$Store))
features = c("Store","Dept","IsHoliday","Type_A","Type_B","Type_C","Size","Temperature","Fuel_Price","MarkDown1","MarkDown2","MarkDown3","MarkDown4","MarkDown5","CPI","Unemployment","Year","Month","Day")
correlation = cor(select(dataset,features))
```

```{r}
dataset_pca = prcomp(select(dataset,features), scale=TRUE)
dataset_pca
```

```{r}
summary(dataset_pca)
```

```{r}
#Recreating the summary table manually
dataset_eigen = dataset_pca$sdev^2
names(dataset_eigen) <- paste("PC",1:19,sep="")
dataset_eigen

```
```{r}
sumlambdas = sum(dataset_eigen)
sumlambdas
```

```{r}
propvar = dataset_eigen/sumlambdas
propvar

```

```{r}
dataset_cumvar <- cumsum(propvar)
dataset_cumvar
```

```{r}
matlambdas <- rbind(dataset_eigen,propvar,dataset_cumvar)
rownames(matlambdas) <- c("Eigenvalues","Prop. variance","Cum. prop. variance")
round(matlambdas,4)
```

```{r}
summary(dataset_pca)
```
```{r}
dataset_pca$rotation
```

```{r}
print(dataset_pca)
```

```{r}
#1st Option Based on retating components that account for 70% to 90% of the variance, we need to retain PC1 to PC8 or PC1 to PC12.
#2nd Option Based on the rule of sum to choose all components with eigen values larger than 0.7, we need to retain PC1 to PC12.
dataset_pca$x

```

```{r}
weeklySales <- data.frame(WeeklySales=dataset$weeklySales) 
dataset2_pca <- cbind(weeklySales, dataset_pca$x)
dataset2_pca 
```

```{r}
tabmeansPC <- aggregate(dataset2_pca[,2:13],by=list(weeklySales=dataset$weeklySales),mean) 
tabmeansPC 
```

```{r}
tabmeansPC <- tabmeansPC[rev(order(tabmeansPC$weeklySales)),] 
tabmeansPC 
```

```{r}
summary(dataset_pca) 
```
```{r}
eigvec.dataset<-dataset_pca$rotation
print(eigvec.dataset)

```

```{r}
# Taking the first three PCs to generate linear combinations for all the variables with three factors
pcafactors.dataset <- eigvec.dataset[,1:3]
pcafactors.dataset

```

```{r}
# Multiplying each column of the eigenvector's matrix by the square-root of the corresponding eigenvalue in order to get the factor loadings
unrot.fact.dataset <- sweep(pcafactors.dataset,MARGIN=2,dataset_pca$sdev[1:3],`*`)
unrot.fact.dataset
```

```{r}
# Computing communalities
communalities.dataset <- rowSums(unrot.fact.dataset^2)
communalities.dataset
```

```{r}
# Performing the varimax rotation. The default in the varimax function is norm=TRUE thus, Kaiser normalization is carried out
rot.fact.dataset <- varimax(unrot.fact.dataset)
View(unrot.fact.dataset)
rot.fact.dataset
```

```{r}
# The print method of varimax omits loadings less than abs(0.1). In order to display all the loadings, it is necessary to ask explicitly the contents of the object $loadings
fact.load.dataset <- rot.fact.dataset$loadings[1:7,1:3]
fact.load.dataset
```

```{r}
# Computing the rotated factor scores
scale.dataset <- scale(select(dataset,features))
scale.dataset

```

```{r}
as.matrix(scale.dataset)
fact.load.dataset
solve(t(fact.load.dataset)%*%fact.load.dataset)
```

```{r}
fit.pc <- principal((select(dataset,features)), nfactors=3, rotate="varimax")
fit.pc

```

```{r}
round(fit.pc$values, 3)
```
```{r}
fit.pc$loadings
```

```{r}
# Loadings with more digits
pc.load.dataset <- fit.pc$loadings[1:7,1:3]
print(pc.load.dataset)
```

```{r}
# Communalities
fit.pc$communality
```

```{r}
# Rotated factor scores
fit.pc$scores

```

```{r}
# Factor Analysis utilities

fa.parallel(select(dataset,features)) 
```
```{r}
#Based on the plot, we should retain two factors(based on the first elbow)
fa.plot(fit.pc) 

```
```{r}
fa.diagram(fit.pc) 
```
```{r}
#This diagram visualizes the relationship

vss(select(dataset,features)) 

```


